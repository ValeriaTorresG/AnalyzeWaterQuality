{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c9be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import optuna\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "from dataclasses import dataclass, field\n",
    "from skimage.util import view_as_windows\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['text.usetex'] = True\n",
    "os.environ['PATH'] = '/Library/TeX/texbin:' + os.environ['PATH']\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1739b86",
   "metadata": {},
   "source": [
    "# old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2062b9",
   "metadata": {},
   "source": [
    "#### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SatelliteDataset(Dataset):\n",
    "\n",
    "    images: np.ndarray\n",
    "    masks: np.ndarray\n",
    "    transform: Optional[callable] = None\n",
    "\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406, 0.5], dtype=torch.float32)[:, None, None]\n",
    "    std = torch.tensor([0.229, 0.224, 0.225, 0.25], dtype=torch.float32)[:, None, None]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img = torch.from_numpy(self.images[idx]).float()\n",
    "        img = (img - self.mean) / self.std\n",
    "        msk = torch.from_numpy(self.masks[idx]).float()\n",
    "\n",
    "        while msk.ndim > 2:\n",
    "            msk = msk.squeeze(0)\n",
    "        msk = msk.unsqueeze(0)\n",
    "        return img, msk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10afa3",
   "metadata": {},
   "source": [
    "#### layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def __hash__(self): #make instance hashable by its id\n",
    "        return id(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e9ade2",
   "metadata": {},
   "source": [
    "#### simple unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd1572",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=5, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "            self.downs.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def __hash__(self): #make instance hashable by its id\n",
    "        return id(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip = []\n",
    "        for idx in range(0, len(self.downs), 2):\n",
    "            conv = self.downs[idx](x)\n",
    "            skip.append(conv)\n",
    "            x = self.downs[idx+1](conv)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip = skip[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            sc = skip[idx//2]\n",
    "            if x.shape[2:] != sc.shape[2:]:\n",
    "                x = F.interpolate(x, size=sc.shape[2:], mode='nearest')\n",
    "            x = torch.cat([sc, x], dim=1)\n",
    "            x = self.ups[idx+1](x)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d908da46",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ab2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, train_loader: DataLoader,\n",
    "                val_loader: DataLoader, device: torch.device,\n",
    "                epochs: int = 50, lr: float = 1e-4):\n",
    "\n",
    "    criterion = nn.MSELoss() #! check this------\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "\n",
    "    tl, tt = [], []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for imgs, masks in train_loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, masks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * imgs.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        tl.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in val_loader:\n",
    "                imgs, masks = imgs.to(device), masks.to(device)\n",
    "                preds = model(imgs)\n",
    "                loss = criterion(preds, masks)\n",
    "                val_loss += loss.item() * imgs.size(0)\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            tt.append(val_loss)\n",
    "\n",
    "        # print(f'epoch {epoch}/{epochs}, train:{train_loss:.4f}, val: {val_loss:.4f}')\n",
    "    return tl, tt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5ef16",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('chesapeake_dataset.npz')\n",
    "\n",
    "X = np.array([dataset['B2'], dataset['B3'], dataset['B4'], dataset['B8']])\n",
    "y = dataset['in_situ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f14ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['B2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f49377",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe3dff",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e36749",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.stack([dataset['B2'], dataset['B3'], dataset['B4'], dataset['B8']], axis=-1)\n",
    "print(\"images.shape =\", images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_shape = (patch_size, patch_size, images.shape[2])  # (43,43,4)\n",
    "step = (step_spatial, step_spatial, images.shape[2])\n",
    "\n",
    "patches = view_as_windows(\n",
    "    images,\n",
    "    window_shape=window_shape,\n",
    "    step=step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644478f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03694fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 43\n",
    "step = 43\n",
    "\n",
    "img_patches = view_as_windows(images,\n",
    "                              window_shape=(patch_size, patch_size, 4),\n",
    "                              step=step\n",
    "                              )\n",
    "img_patches = img_patches.reshape(-1, patch_size, patch_size, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b329cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_patches = view_as_windows(mask,\n",
    "                               window_shape=(patch_size, patch_size),\n",
    "                               step=step\n",
    "                               )\n",
    "\n",
    "mask_patches = mask_patches.reshape(-1, patch_size, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.transpose(img_patches, (0, 3, 1, 2))\n",
    "y = mask_patches[:, None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[0]\n",
    "split_idx = int(0.8 * N)\n",
    "train_imgs, val_imgs = X[:split_idx], X[split_idx:]\n",
    "train_masks, val_masks = y[:split_idx], y[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb81de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs.shape, val_imgs.shape, train_masks.shape, val_masks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ad400",
   "metadata": {},
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1583f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(0.8 * len(X))\n",
    "train_imgs, val_imgs = X[:split_idx], X[split_idx:]\n",
    "train_masks, val_masks = y[:split_idx], y[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf56b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[0]\n",
    "train_frac = 0.8\n",
    "split_idx = math.ceil(train_frac * N)  # ceil(0.8 * 1) == 1\n",
    "\n",
    "train_imgs, val_imgs = X[:split_idx], X[split_idx:]\n",
    "train_masks, val_masks = y[:split_idx], y[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b2f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs.shape, val_imgs.shape, train_masks.shape, val_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae890b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406, 0.5, 0.5],\n",
    "                                                     std=[0.229, 0.224, 0.225, 0.25, 0.25])\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5950c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SatelliteDataset(train_imgs, train_masks, transform=transform)\n",
    "val_dataset = SatelliteDataset(val_imgs, val_masks, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c859087",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598fcc1",
   "metadata": {},
   "source": [
    "use mps for metal acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c801aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9564c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e27449f",
   "metadata": {},
   "source": [
    "#### try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8adfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=4, out_channels=1)\n",
    "model.to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl,tt = train_model(model, train_loader, val_loader, device, epochs=50, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c462b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1, 51)\n",
    "plt.plot(epochs, tl, label='train')\n",
    "plt.plot(epochs, tt, label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda1e80",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b434f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelOptimizer:\n",
    "    x_train: np.ndarray\n",
    "    y_train: np.ndarray\n",
    "    x_val: np.ndarray\n",
    "    y_val: np.ndarray\n",
    "    best_params: Dict = field(default_factory=dict)\n",
    "\n",
    "    def objective(self, trial):\n",
    "        lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "        epochs = trial.suggest_int('epochs', 10, 500)\n",
    "        # batch_size = trial.suggest_int('batch_size', 4, 32)\n",
    "\n",
    "        model = UNet(in_channels=4, out_channels=1)\n",
    "        model.to(device, dtype=torch.float32)\n",
    "\n",
    "        train_dataset = SatelliteDataset(self.x_train, self.y_train)\n",
    "        val_dataset = SatelliteDataset(self.x_val, self.y_val)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "        tl, tt = train_model(model, train_loader, val_loader, device, epochs=epochs, lr=lr)\n",
    "        val_loss = tt[-1]\n",
    "        # r2 = r2_score(self.y_val.flatten(), model(self.x_val).flatten().cpu().numpy())\n",
    "        # print(f'val_loss: {val_loss:.4f}, r2: {r2:.4f}')\n",
    "        return val_loss\n",
    "\n",
    "    def optimize(self, n_trials):\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(self.objective, n_trials=n_trials)\n",
    "        self.best_params = study.best_params\n",
    "        print(f'Best params: {self.best_params}')\n",
    "        return self.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5477d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = ModelOptimizer(x_train=train_imgs, y_train=train_masks,\n",
    "                       x_val=val_imgs, y_val=val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354992e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = study.optimize(n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {'lr': 0.002099322607285872, 'epochs': 396}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19949c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=4, out_channels=1)\n",
    "model.to(device, dtype=torch.float32)\n",
    "tl,tt = train_model(model, train_loader, val_loader, device, epochs=best['epochs'], lr=best['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1, best['epochs']+1)\n",
    "\n",
    "plt.plot(epochs, tl, label='train')\n",
    "plt.plot(epochs, tt, label='val')\n",
    "plt.title(f\"Best params: {best}\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim(1, 10)\n",
    "plt.grid(linewidth=0.1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2999d",
   "metadata": {},
   "source": [
    "# new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de70298",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('chesapeake_patches.npz')\n",
    "images = data['images']        # (N, C, H, W)\n",
    "masks = data['masks']          # (N, H, W)\n",
    "\n",
    "masks = masks[:, None, :, :]   # (N, 1, H, W)\n",
    "\n",
    "N = images.shape[0]\n",
    "split = int(0.8 * N)\n",
    "train_imgs, val_imgs   = images[:split], images[split:]\n",
    "train_masks, val_masks = masks[:split], masks[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85225ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation((0, 270)),  # rotaciones de 0,90,180,270°\n",
    "])\n",
    "\n",
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, imgs, msks):\n",
    "        self.images  = torch.from_numpy(imgs).float()\n",
    "        self.masks   = torch.from_numpy(msks).float()\n",
    "        self.augment = augment\n",
    "\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406, 0.5])[..., None, None]\n",
    "        self.std  = torch.tensor([0.229, 0.224, 0.225, 0.25])[..., None, None]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.images[idx]   # (4, H, W)\n",
    "        y = self.masks[idx]    # (1, H, W)\n",
    "        stacked = torch.cat([x, y], dim=0)     # (5, H, W)\n",
    "        stacked = self.augment(stacked)\n",
    "        x_aug, y_aug = stacked[:-1], stacked[-1:]\n",
    "        # x_aug = (x_aug - self.mean) / self.std\n",
    "        return x_aug, y_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0faf16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SatelliteDataset(train_imgs, train_masks)\n",
    "val_ds   = SatelliteDataset(val_imgs, val_masks)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e1971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=1, features=[64,128,256,512]):\n",
    "        super().__init__()\n",
    "        self.downs, self.ups = nn.ModuleList(), nn.ModuleList()\n",
    "        c = in_channels\n",
    "        for f in features:\n",
    "            self.downs.append(DoubleConv(c, f))\n",
    "            self.downs.append(nn.MaxPool2d(2))\n",
    "            c = f\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        for f in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(f*2, f, 2, stride=2))\n",
    "            self.ups.append(DoubleConv(f*2, f))\n",
    "        self.final = nn.Conv2d(features[0], out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skips = []\n",
    "\n",
    "        for i in range(0, len(self.downs), 2):\n",
    "            x = self.downs[i](x)\n",
    "            skips.append(x)\n",
    "            x = self.downs[i+1](x)\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        for i in range(0, len(self.ups), 2):\n",
    "            x = self.ups[i](x)\n",
    "            skip = skips[-(i//2)-1]\n",
    "            if x.shape[2:] != skip.shape[2:]:\n",
    "                x = F.interpolate(x, size=skip.shape[2:], mode='nearest')\n",
    "            x = torch.cat([skip, x], dim=1)\n",
    "            x = self.ups[i+1](x)\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(logits, targets, alpha=0.25, gamma=2.0, eps=1e-6):\n",
    "    prob = torch.sigmoid(logits)\n",
    "    ce   = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "    p_t  = prob*targets + (1-prob)*(1-targets)\n",
    "    loss = alpha * (1 - p_t).pow(gamma) * ce\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a1d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, epochs=30, lr=1e-4, wd=1e-5):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "             mode='min', factor=0.5, patience=3)\n",
    "    best_loss = float('inf')\n",
    "    patience, wait = 10, 0\n",
    "\n",
    "    tl, tt = [], []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for imgs, msks in train_loader:\n",
    "            imgs, msks = imgs.to(device), msks.to(device)\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, msks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * imgs.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        tl.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for imgs, msks in val_loader:\n",
    "                imgs, msks = imgs.to(device), msks.to(device)\n",
    "                preds = model(imgs)\n",
    "                val_loss += criterion(preds, msks).item() * imgs.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        tt.append(val_loss)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss, wait = val_loss, 0\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"No hubo mejora en {patience} épocas, deteniendo.\")\n",
    "                model.load_state_dict(torch.load('best_model.pt'))\n",
    "                break\n",
    "\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} — train {train_loss:.4f}, val {val_loss:.4f}\")\n",
    "    return model, tl, tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ecabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd90956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet(in_channels=4, out_channels=1)\n",
    "# en lugar de [64,128,256,512], prueba [32,64,128,256]\n",
    "model = UNet(in_channels=4, out_channels=1, features=[32,64,128,256])\n",
    "\n",
    "trained_model, tl, tt = train_model(model, train_loader, val_loader,\n",
    "                                    device, epochs=200, lr=1e-4,\n",
    "                                    wd=1e-6)\n",
    "\n",
    "epochs = np.arange(1, len(tl)+1)\n",
    "plt.plot(epochs, tl, label='train')\n",
    "plt.plot(epochs, tt, label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ebfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=4, out_channels=1, features=[32,64,128,256])\n",
    "\n",
    "trained_model, tl, tt = train_model(model, train_loader, val_loader,\n",
    "                                    device, epochs=200, lr=1e-5,\n",
    "                                    wd=1e-6)\n",
    "\n",
    "epochs = np.arange(1, len(tl)+1)\n",
    "plt.plot(epochs, tl, label='train')\n",
    "plt.plot(epochs, tt, label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1865843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=4, out_channels=1, features=[32,64,128,256])\n",
    "\n",
    "trained_model, tl, tt = train_model(model, train_loader, val_loader,\n",
    "                                    device, epochs=200, lr=1e-5,\n",
    "                                    wd=0)\n",
    "\n",
    "epochs = np.arange(1, len(tl)+1)\n",
    "plt.plot(epochs, tl, label='train')\n",
    "plt.plot(epochs, tt, label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aad6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=4, out_channels=1, features=[32,64,128,256])\n",
    "\n",
    "trained_model, tl, tt = train_model(model, train_loader, val_loader,\n",
    "                                    device, epochs=200, lr=5e-4,\n",
    "                                    wd=5e-6)\n",
    "\n",
    "epochs = np.arange(1, len(tl)+1)\n",
    "plt.plot(epochs, tl, label='train')\n",
    "plt.plot(epochs, tt, label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402da244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=4, out_channels=1, features=[32,64,128,256])\n",
    "\n",
    "trained_model, tl, tt = train_model(model, train_loader, val_loader,\n",
    "                                    device, epochs=200, lr=5e-4,\n",
    "                                    wd=5e-6)\n",
    "\n",
    "epochs = np.arange(1, len(tl)+1)\n",
    "plt.plot(epochs, tl, label='train')\n",
    "plt.plot(epochs, tt, label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=4, out_channels=1, features=[32,64,128,256])\n",
    "\n",
    "trained_model, tl, tt = train_model(model, train_loader, val_loader,\n",
    "                                    device, epochs=200, lr=1e-4,\n",
    "                                    wd=5e-3)\n",
    "\n",
    "epochs = np.arange(1, len(tl)+1)\n",
    "plt.plot(epochs, tl, label='train')\n",
    "plt.plot(epochs, tt, label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453069d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(logits, mask, eps=1e-6):\n",
    "    \"\"\"Intersection over Union para un batch (promediada).\"\"\"\n",
    "    preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "    mask  = mask.float()\n",
    "    inter = (preds * mask).sum(dim=(2,3))\n",
    "    union = (preds + mask - preds*mask).sum(dim=(2,3))\n",
    "    return ((inter + eps)/(union + eps)).mean().item()\n",
    "\n",
    "def dice_score(logits, mask, eps=1e-6):\n",
    "    \"\"\"Dice Coefficient (promediada).\"\"\"\n",
    "    prob  = torch.sigmoid(logits)\n",
    "    inter = (prob * mask).sum(dim=(2,3))\n",
    "    union = prob.sum((2,3)) + mask.sum((2,3))\n",
    "    return ((2*inter + eps)/(union + eps)).mean().item()\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, device,\n",
    "                       epochs=30, lr=1e-4, weight_decay=1e-5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3\n",
    "    )\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    train_losses, val_losses, val_ious = [], [], []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running_train = 0.0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss   = criterion(logits, y) + (1 - dice_score(logits, y))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train += loss.item() * x.size(0)\n",
    "        train_loss = running_train / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        running_val, running_iou = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits = model(x)\n",
    "                loss   = criterion(logits, y) + (1 - dice_score(logits, y))\n",
    "                running_val += loss.item() * x.size(0)\n",
    "                running_iou += iou_score(logits, y) * x.size(0)\n",
    "        val_loss = running_val / len(val_loader.dataset)\n",
    "        val_iou  = running_iou  / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        val_ious.append(val_iou)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} — \"\n",
    "              f\"train: {train_loss:.4f}  \"\n",
    "              f\"val: {val_loss:.4f}  \"\n",
    "              f\"val IoU: {val_iou:.3f}\")\n",
    "\n",
    "    return train_losses, val_losses, val_ious\n",
    "\n",
    "device = torch.device('mps')\n",
    "model = UNet(in_channels=4, out_channels=1, features=[32,64,128,256])\n",
    "\n",
    "model.to(device)\n",
    "tl, vl, vi = train_and_evaluate(model, train_loader, val_loader, device,\n",
    "                                epochs=30, lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(tl)+1), tl, label='train loss')\n",
    "plt.plot(range(1, len(vl)+1), vl, label='val loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Train vs Val Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(vi)+1), vi, label='val IoU')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('IoU')\n",
    "plt.legend()\n",
    "plt.title('Validation IoU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_metrics(model, loader, device):\n",
    "    \"\"\"\n",
    "    Evalúa accuracy, precision, recall y F1-score\n",
    "    sobre un DataLoader de validación.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            logits = model(imgs)\n",
    "\n",
    "            probs = torch.sigmoid(logits).cpu().numpy().flatten()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "            labels = masks.cpu().numpy().flatten().astype(int)\n",
    "\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    acc  = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    prec = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    rec  = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1   = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "device = torch.device('mps')\n",
    "acc, prec, rec, f1 = evaluate_classification_metrics(\n",
    "    model, val_loader, device\n",
    ")\n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(f\"F1-score:  {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae9428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, device,\n",
    "                       train_losses, val_losses, val_ious,\n",
    "                       epochs=30, lr=1e-4, weight_decay=1e-5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3\n",
    "    )\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running_train = 0.0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss   = criterion(logits, y) + (1 - dice_score(logits, y))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train += loss.item() * x.size(0)\n",
    "        train_loss = running_train / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        running_val, running_iou = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits = model(x)\n",
    "                loss   = criterion(logits, y) + (1 - dice_score(logits, y))\n",
    "                running_val += loss.item() * x.size(0)\n",
    "                running_iou += iou_score(logits, y) * x.size(0)\n",
    "        val_loss = running_val / len(val_loader.dataset)\n",
    "        val_iou  = running_iou  / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        val_ious.append(val_iou)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} — \"\n",
    "              f\"train: {train_loss:.4f}  \"\n",
    "              f\"val: {val_loss:.4f}  \"\n",
    "              f\"val IoU: {val_iou:.3f}\")\n",
    "\n",
    "    return train_losses, val_losses, val_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02906f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "tl_, vl_, vi_ = train_and_evaluate(model, train_loader, val_loader, device,\n",
    "                                tl, vl, vi,\n",
    "                                epochs=30, lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(tl_)+1), tl_, label='train loss')\n",
    "plt.plot(range(1, len(vl_)+1), vl_, label='val loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Train vs Val Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(vi_)+1), vi_, label='val IoU')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('IoU')\n",
    "plt.legend()\n",
    "plt.title('Validation IoU')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
